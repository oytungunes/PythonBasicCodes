{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoEncoderExample.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+icCVr2GlIt60+a1HIePj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oytungunes/PythonCodeExamples/blob/main/AutoEncoderExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoOiXR9EB4zf"
      },
      "source": [
        "Autoencoder is a type of neural network that can be used to learn a compressed representation of raw data.\n",
        "\n",
        "An autoencoder is composed of an encoder and a decoder sub-models. The encoder compresses the input and the decoder attempts to recreate the input from the compressed version provided by the encoder. After training, the encoder model is saved and the decoder is discarded.\n",
        "\n",
        "The encoder can then be used as a data preparation technique to perform feature extraction on raw data that can be used to train a different machine learning model.\n",
        "\n",
        "\n",
        "This example i\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1T7y8kTQB5HX",
        "outputId": "1d3e724b-146d-47da-d2e3-b99b9385272c"
      },
      "source": [
        "# train autoencoder for classification with no compression in the bottleneck layer\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\n",
        "# number of input columns\n",
        "n_inputs = X.shape[1]\n",
        "# split into train test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# scale data\n",
        "t = MinMaxScaler()\n",
        "t.fit(X_train)\n",
        "X_train = t.transform(X_train)\n",
        "X_test = t.transform(X_test)\n",
        "# define encoder\n",
        "visible = Input(shape=(n_inputs,))\n",
        "# encoder level 1\n",
        "e = Dense(n_inputs*2)(visible)\n",
        "e = BatchNormalization()(e)\n",
        "e = LeakyReLU()(e)\n",
        "# encoder level 2\n",
        "e = Dense(n_inputs)(e)\n",
        "e = BatchNormalization()(e)\n",
        "e = LeakyReLU()(e)\n",
        "# bottleneck\n",
        "n_bottleneck = n_inputs\n",
        "bottleneck = Dense(n_bottleneck)(e)\n",
        "# define decoder, level 1\n",
        "d = Dense(n_inputs)(bottleneck)\n",
        "d = BatchNormalization()(d)\n",
        "d = LeakyReLU()(d)\n",
        "# decoder level 2\n",
        "d = Dense(n_inputs*2)(d)\n",
        "d = BatchNormalization()(d)\n",
        "d = LeakyReLU()(d)\n",
        "# output layer\n",
        "output = Dense(n_inputs, activation='linear')(d)\n",
        "# define autoencoder model\n",
        "model = Model(inputs=visible, outputs=output)\n",
        "# compile autoencoder model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# plot the autoencoder\n",
        "plot_model(model, 'autoencoder_no_compress.png', show_shapes=True)\n",
        "# fit the autoencoder model to reconstruct input\n",
        "history = model.fit(X_train, X_train, epochs=200, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n",
        "# plot loss\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "# define an encoder model (without the decoder)\n",
        "encoder = Model(inputs=visible, outputs=bottleneck)\n",
        "plot_model(encoder, 'encoder_no_compress.png', show_shapes=True)\n",
        "# save the encoder to file\n",
        "encoder.save('encoder.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "42/42 - 2s - loss: 0.2338 - val_loss: 0.1677\n",
            "Epoch 2/200\n",
            "42/42 - 0s - loss: 0.0388 - val_loss: 0.0989\n",
            "Epoch 3/200\n",
            "42/42 - 0s - loss: 0.0232 - val_loss: 0.0508\n",
            "Epoch 4/200\n",
            "42/42 - 0s - loss: 0.0183 - val_loss: 0.0292\n",
            "Epoch 5/200\n",
            "42/42 - 0s - loss: 0.0159 - val_loss: 0.0199\n",
            "Epoch 6/200\n",
            "42/42 - 0s - loss: 0.0143 - val_loss: 0.0149\n",
            "Epoch 7/200\n",
            "42/42 - 0s - loss: 0.0135 - val_loss: 0.0108\n",
            "Epoch 8/200\n",
            "42/42 - 0s - loss: 0.0117 - val_loss: 0.0087\n",
            "Epoch 9/200\n",
            "42/42 - 0s - loss: 0.0106 - val_loss: 0.0070\n",
            "Epoch 10/200\n",
            "42/42 - 0s - loss: 0.0109 - val_loss: 0.0080\n",
            "Epoch 11/200\n",
            "42/42 - 0s - loss: 0.0104 - val_loss: 0.0063\n",
            "Epoch 12/200\n",
            "42/42 - 0s - loss: 0.0097 - val_loss: 0.0057\n",
            "Epoch 13/200\n",
            "42/42 - 0s - loss: 0.0096 - val_loss: 0.0057\n",
            "Epoch 14/200\n",
            "42/42 - 0s - loss: 0.0083 - val_loss: 0.0052\n",
            "Epoch 15/200\n",
            "42/42 - 0s - loss: 0.0086 - val_loss: 0.0060\n",
            "Epoch 16/200\n",
            "42/42 - 0s - loss: 0.0084 - val_loss: 0.0047\n",
            "Epoch 17/200\n",
            "42/42 - 0s - loss: 0.0079 - val_loss: 0.0058\n",
            "Epoch 18/200\n",
            "42/42 - 0s - loss: 0.0080 - val_loss: 0.0048\n",
            "Epoch 19/200\n",
            "42/42 - 0s - loss: 0.0080 - val_loss: 0.0047\n",
            "Epoch 20/200\n",
            "42/42 - 0s - loss: 0.0077 - val_loss: 0.0042\n",
            "Epoch 21/200\n",
            "42/42 - 0s - loss: 0.0069 - val_loss: 0.0036\n",
            "Epoch 22/200\n",
            "42/42 - 0s - loss: 0.0073 - val_loss: 0.0034\n",
            "Epoch 23/200\n",
            "42/42 - 0s - loss: 0.0068 - val_loss: 0.0036\n",
            "Epoch 24/200\n",
            "42/42 - 0s - loss: 0.0071 - val_loss: 0.0039\n",
            "Epoch 25/200\n",
            "42/42 - 0s - loss: 0.0068 - val_loss: 0.0039\n",
            "Epoch 26/200\n",
            "42/42 - 0s - loss: 0.0066 - val_loss: 0.0046\n",
            "Epoch 27/200\n",
            "42/42 - 0s - loss: 0.0065 - val_loss: 0.0030\n",
            "Epoch 28/200\n",
            "42/42 - 0s - loss: 0.0065 - val_loss: 0.0043\n",
            "Epoch 29/200\n",
            "42/42 - 0s - loss: 0.0065 - val_loss: 0.0056\n",
            "Epoch 30/200\n",
            "42/42 - 0s - loss: 0.0067 - val_loss: 0.0037\n",
            "Epoch 31/200\n",
            "42/42 - 0s - loss: 0.0066 - val_loss: 0.0030\n",
            "Epoch 32/200\n",
            "42/42 - 0s - loss: 0.0056 - val_loss: 0.0040\n",
            "Epoch 33/200\n",
            "42/42 - 0s - loss: 0.0061 - val_loss: 0.0034\n",
            "Epoch 34/200\n",
            "42/42 - 0s - loss: 0.0060 - val_loss: 0.0037\n",
            "Epoch 35/200\n",
            "42/42 - 0s - loss: 0.0058 - val_loss: 0.0029\n",
            "Epoch 36/200\n",
            "42/42 - 0s - loss: 0.0062 - val_loss: 0.0033\n",
            "Epoch 37/200\n",
            "42/42 - 0s - loss: 0.0060 - val_loss: 0.0024\n",
            "Epoch 38/200\n",
            "42/42 - 0s - loss: 0.0059 - val_loss: 0.0032\n",
            "Epoch 39/200\n",
            "42/42 - 0s - loss: 0.0057 - val_loss: 0.0037\n",
            "Epoch 40/200\n",
            "42/42 - 0s - loss: 0.0058 - val_loss: 0.0033\n",
            "Epoch 41/200\n",
            "42/42 - 0s - loss: 0.0060 - val_loss: 0.0026\n",
            "Epoch 42/200\n",
            "42/42 - 0s - loss: 0.0057 - val_loss: 0.0037\n",
            "Epoch 43/200\n",
            "42/42 - 0s - loss: 0.0059 - val_loss: 0.0031\n",
            "Epoch 44/200\n",
            "42/42 - 0s - loss: 0.0054 - val_loss: 0.0032\n",
            "Epoch 45/200\n",
            "42/42 - 0s - loss: 0.0055 - val_loss: 0.0027\n",
            "Epoch 46/200\n",
            "42/42 - 0s - loss: 0.0050 - val_loss: 0.0020\n",
            "Epoch 47/200\n",
            "42/42 - 0s - loss: 0.0053 - val_loss: 0.0033\n",
            "Epoch 48/200\n",
            "42/42 - 0s - loss: 0.0053 - val_loss: 0.0025\n",
            "Epoch 49/200\n",
            "42/42 - 0s - loss: 0.0053 - val_loss: 0.0026\n",
            "Epoch 50/200\n",
            "42/42 - 0s - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 51/200\n",
            "42/42 - 0s - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 52/200\n",
            "42/42 - 0s - loss: 0.0057 - val_loss: 0.0031\n",
            "Epoch 53/200\n",
            "42/42 - 0s - loss: 0.0053 - val_loss: 0.0026\n",
            "Epoch 54/200\n",
            "42/42 - 0s - loss: 0.0053 - val_loss: 0.0025\n",
            "Epoch 55/200\n",
            "42/42 - 0s - loss: 0.0051 - val_loss: 0.0031\n",
            "Epoch 56/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0021\n",
            "Epoch 57/200\n",
            "42/42 - 0s - loss: 0.0049 - val_loss: 0.0030\n",
            "Epoch 58/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0022\n",
            "Epoch 59/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0032\n",
            "Epoch 60/200\n",
            "42/42 - 0s - loss: 0.0051 - val_loss: 0.0028\n",
            "Epoch 61/200\n",
            "42/42 - 0s - loss: 0.0050 - val_loss: 0.0024\n",
            "Epoch 62/200\n",
            "42/42 - 0s - loss: 0.0049 - val_loss: 0.0024\n",
            "Epoch 63/200\n",
            "42/42 - 0s - loss: 0.0047 - val_loss: 0.0034\n",
            "Epoch 64/200\n",
            "42/42 - 0s - loss: 0.0051 - val_loss: 0.0030\n",
            "Epoch 65/200\n",
            "42/42 - 0s - loss: 0.0052 - val_loss: 0.0025\n",
            "Epoch 66/200\n",
            "42/42 - 0s - loss: 0.0044 - val_loss: 0.0026\n",
            "Epoch 67/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0020\n",
            "Epoch 68/200\n",
            "42/42 - 0s - loss: 0.0050 - val_loss: 0.0024\n",
            "Epoch 69/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0034\n",
            "Epoch 70/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0026\n",
            "Epoch 71/200\n",
            "42/42 - 0s - loss: 0.0047 - val_loss: 0.0028\n",
            "Epoch 72/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0030\n",
            "Epoch 73/200\n",
            "42/42 - 0s - loss: 0.0046 - val_loss: 0.0023\n",
            "Epoch 74/200\n",
            "42/42 - 0s - loss: 0.0052 - val_loss: 0.0031\n",
            "Epoch 75/200\n",
            "42/42 - 0s - loss: 0.0046 - val_loss: 0.0025\n",
            "Epoch 76/200\n",
            "42/42 - 0s - loss: 0.0046 - val_loss: 0.0025\n",
            "Epoch 77/200\n",
            "42/42 - 0s - loss: 0.0050 - val_loss: 0.0018\n",
            "Epoch 78/200\n",
            "42/42 - 0s - loss: 0.0047 - val_loss: 0.0018\n",
            "Epoch 79/200\n",
            "42/42 - 0s - loss: 0.0045 - val_loss: 0.0019\n",
            "Epoch 80/200\n",
            "42/42 - 0s - loss: 0.0044 - val_loss: 0.0026\n",
            "Epoch 81/200\n",
            "42/42 - 0s - loss: 0.0048 - val_loss: 0.0026\n",
            "Epoch 82/200\n",
            "42/42 - 0s - loss: 0.0047 - val_loss: 0.0022\n",
            "Epoch 83/200\n",
            "42/42 - 0s - loss: 0.0047 - val_loss: 0.0018\n",
            "Epoch 84/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0019\n",
            "Epoch 85/200\n",
            "42/42 - 0s - loss: 0.0045 - val_loss: 0.0019\n",
            "Epoch 86/200\n",
            "42/42 - 0s - loss: 0.0042 - val_loss: 0.0026\n",
            "Epoch 87/200\n",
            "42/42 - 0s - loss: 0.0046 - val_loss: 0.0023\n",
            "Epoch 88/200\n",
            "42/42 - 0s - loss: 0.0045 - val_loss: 0.0024\n",
            "Epoch 89/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0021\n",
            "Epoch 90/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0023\n",
            "Epoch 91/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0021\n",
            "Epoch 92/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0016\n",
            "Epoch 93/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0025\n",
            "Epoch 94/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0026\n",
            "Epoch 95/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0026\n",
            "Epoch 96/200\n",
            "42/42 - 0s - loss: 0.0040 - val_loss: 0.0021\n",
            "Epoch 97/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0024\n",
            "Epoch 98/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0019\n",
            "Epoch 99/200\n",
            "42/42 - 0s - loss: 0.0037 - val_loss: 0.0020\n",
            "Epoch 100/200\n",
            "42/42 - 0s - loss: 0.0042 - val_loss: 0.0020\n",
            "Epoch 101/200\n",
            "42/42 - 0s - loss: 0.0040 - val_loss: 0.0020\n",
            "Epoch 102/200\n",
            "42/42 - 0s - loss: 0.0047 - val_loss: 0.0022\n",
            "Epoch 103/200\n",
            "42/42 - 0s - loss: 0.0043 - val_loss: 0.0021\n",
            "Epoch 104/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0029\n",
            "Epoch 105/200\n",
            "42/42 - 0s - loss: 0.0044 - val_loss: 0.0017\n",
            "Epoch 106/200\n",
            "42/42 - 0s - loss: 0.0042 - val_loss: 0.0023\n",
            "Epoch 107/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0016\n",
            "Epoch 108/200\n",
            "42/42 - 0s - loss: 0.0040 - val_loss: 0.0019\n",
            "Epoch 109/200\n",
            "42/42 - 0s - loss: 0.0039 - val_loss: 0.0018\n",
            "Epoch 110/200\n",
            "42/42 - 0s - loss: 0.0037 - val_loss: 0.0017\n",
            "Epoch 111/200\n",
            "42/42 - 0s - loss: 0.0039 - val_loss: 0.0018\n",
            "Epoch 112/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0019\n",
            "Epoch 113/200\n",
            "42/42 - 0s - loss: 0.0040 - val_loss: 0.0027\n",
            "Epoch 114/200\n",
            "42/42 - 0s - loss: 0.0040 - val_loss: 0.0019\n",
            "Epoch 115/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0021\n",
            "Epoch 116/200\n",
            "42/42 - 0s - loss: 0.0044 - val_loss: 0.0018\n",
            "Epoch 117/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0013\n",
            "Epoch 118/200\n",
            "42/42 - 0s - loss: 0.0042 - val_loss: 0.0021\n",
            "Epoch 119/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0019\n",
            "Epoch 120/200\n",
            "42/42 - 0s - loss: 0.0042 - val_loss: 0.0018\n",
            "Epoch 121/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0021\n",
            "Epoch 122/200\n",
            "42/42 - 0s - loss: 0.0039 - val_loss: 0.0021\n",
            "Epoch 123/200\n",
            "42/42 - 0s - loss: 0.0037 - val_loss: 0.0020\n",
            "Epoch 124/200\n",
            "42/42 - 0s - loss: 0.0042 - val_loss: 0.0024\n",
            "Epoch 125/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0013\n",
            "Epoch 126/200\n",
            "42/42 - 0s - loss: 0.0039 - val_loss: 0.0028\n",
            "Epoch 127/200\n",
            "42/42 - 0s - loss: 0.0041 - val_loss: 0.0023\n",
            "Epoch 128/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0021\n",
            "Epoch 129/200\n",
            "42/42 - 0s - loss: 0.0040 - val_loss: 0.0021\n",
            "Epoch 130/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0013\n",
            "Epoch 131/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0020\n",
            "Epoch 132/200\n",
            "42/42 - 0s - loss: 0.0040 - val_loss: 0.0016\n",
            "Epoch 133/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0016\n",
            "Epoch 134/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0016\n",
            "Epoch 135/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0019\n",
            "Epoch 136/200\n",
            "42/42 - 0s - loss: 0.0037 - val_loss: 0.0016\n",
            "Epoch 137/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0020\n",
            "Epoch 138/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0017\n",
            "Epoch 139/200\n",
            "42/42 - 0s - loss: 0.0037 - val_loss: 0.0013\n",
            "Epoch 140/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0014\n",
            "Epoch 141/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0019\n",
            "Epoch 142/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0012\n",
            "Epoch 143/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0013\n",
            "Epoch 144/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0020\n",
            "Epoch 145/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0017\n",
            "Epoch 146/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0020\n",
            "Epoch 147/200\n",
            "42/42 - 0s - loss: 0.0037 - val_loss: 0.0018\n",
            "Epoch 148/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0017\n",
            "Epoch 149/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0012\n",
            "Epoch 150/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0022\n",
            "Epoch 151/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0019\n",
            "Epoch 152/200\n",
            "42/42 - 0s - loss: 0.0036 - val_loss: 0.0014\n",
            "Epoch 153/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0013\n",
            "Epoch 154/200\n",
            "42/42 - 0s - loss: 0.0038 - val_loss: 0.0015\n",
            "Epoch 155/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0017\n",
            "Epoch 156/200\n",
            "42/42 - 0s - loss: 0.0039 - val_loss: 0.0017\n",
            "Epoch 157/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0014\n",
            "Epoch 158/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0011\n",
            "Epoch 159/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0015\n",
            "Epoch 160/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0015\n",
            "Epoch 161/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0018\n",
            "Epoch 162/200\n",
            "42/42 - 0s - loss: 0.0029 - val_loss: 0.0015\n",
            "Epoch 163/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0015\n",
            "Epoch 164/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 165/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0018\n",
            "Epoch 166/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0015\n",
            "Epoch 167/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0016\n",
            "Epoch 168/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0016\n",
            "Epoch 169/200\n",
            "42/42 - 0s - loss: 0.0031 - val_loss: 0.0016\n",
            "Epoch 170/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
            "Epoch 171/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0012\n",
            "Epoch 172/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0016\n",
            "Epoch 173/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0012\n",
            "Epoch 174/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0014\n",
            "Epoch 175/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0013\n",
            "Epoch 176/200\n",
            "42/42 - 0s - loss: 0.0035 - val_loss: 0.0024\n",
            "Epoch 177/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0011\n",
            "Epoch 178/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0010\n",
            "Epoch 179/200\n",
            "42/42 - 0s - loss: 0.0030 - val_loss: 0.0013\n",
            "Epoch 180/200\n",
            "42/42 - 0s - loss: 0.0029 - val_loss: 0.0011\n",
            "Epoch 181/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0013\n",
            "Epoch 182/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0012\n",
            "Epoch 183/200\n",
            "42/42 - 0s - loss: 0.0031 - val_loss: 0.0016\n",
            "Epoch 184/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 9.3334e-04\n",
            "Epoch 185/200\n",
            "42/42 - 0s - loss: 0.0030 - val_loss: 0.0014\n",
            "Epoch 186/200\n",
            "42/42 - 0s - loss: 0.0034 - val_loss: 0.0020\n",
            "Epoch 187/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0018\n",
            "Epoch 188/200\n",
            "42/42 - 0s - loss: 0.0028 - val_loss: 0.0013\n",
            "Epoch 189/200\n",
            "42/42 - 0s - loss: 0.0031 - val_loss: 0.0017\n",
            "Epoch 190/200\n",
            "42/42 - 0s - loss: 0.0031 - val_loss: 0.0014\n",
            "Epoch 191/200\n",
            "42/42 - 0s - loss: 0.0030 - val_loss: 0.0012\n",
            "Epoch 192/200\n",
            "42/42 - 0s - loss: 0.0032 - val_loss: 0.0012\n",
            "Epoch 193/200\n",
            "42/42 - 0s - loss: 0.0031 - val_loss: 0.0013\n",
            "Epoch 194/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
            "Epoch 195/200\n",
            "42/42 - 0s - loss: 0.0033 - val_loss: 0.0015\n",
            "Epoch 196/200\n",
            "42/42 - 0s - loss: 0.0031 - val_loss: 9.8627e-04\n",
            "Epoch 197/200\n",
            "42/42 - 0s - loss: 0.0029 - val_loss: 0.0013\n",
            "Epoch 198/200\n",
            "42/42 - 0s - loss: 0.0028 - val_loss: 0.0012\n",
            "Epoch 199/200\n",
            "42/42 - 0s - loss: 0.0030 - val_loss: 0.0011\n",
            "Epoch 200/200\n",
            "42/42 - 0s - loss: 0.0029 - val_loss: 0.0015\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    }
  ]
}